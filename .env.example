# GraphRAG API Service - Environment Configuration Template
# Copy this file to .env and configure your specific values

# =============================================================================
# API CONFIGURATION
# =============================================================================
APP_NAME="GraphRAG API Service"
APP_VERSION="0.1.0"
DEBUG=false

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
HOST="0.0.0.0"
PORT=8001

# =============================================================================
# GRAPHRAG CONFIGURATION
# =============================================================================
# Optional: Path to GraphRAG configuration file
# GRAPHRAG_CONFIG_PATH="/path/to/graphrag/config.yaml"

# Optional: Path to GraphRAG data directory
# GRAPHRAG_DATA_PATH="/path/to/graphrag/data"

# =============================================================================
# LLM PROVIDER SELECTION
# =============================================================================
# Choose your LLM provider: "ollama" or "google_gemini"
# For local development with privacy: use "ollama"
# For cloud deployment with high performance: use "google_gemini"
LLM_PROVIDER="ollama"

# =============================================================================
# OLLAMA CONFIGURATION (Local Provider)
# =============================================================================
# Ollama server configuration for local deployment
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_LLM_MODEL="gemma:4b"
OLLAMA_EMBEDDING_MODEL="nomic-embed-text"

# Prerequisites for Ollama:
# 1. Install Ollama: https://ollama.ai/
# 2. Pull models: ollama pull gemma:4b && ollama pull nomic-embed-text
# 3. Start Ollama service

# =============================================================================
# GOOGLE GEMINI CONFIGURATION (Cloud Provider)
# =============================================================================
# Google Cloud API configuration (required for google_gemini provider)
# GOOGLE_API_KEY="your_google_api_key_here"
# GOOGLE_PROJECT_ID="your_google_cloud_project_id"

# Google Cloud location (default: us-central1)
GOOGLE_LOCATION="us-central1"

# Gemini model configuration
GEMINI_MODEL="gemini-2.5-flash"
GEMINI_EMBEDDING_MODEL="text-embedding-004"

# =============================================================================
# VERTEX AI CONFIGURATION (Advanced Google Cloud)
# =============================================================================
# Enable Vertex AI endpoints instead of standard Gemini API
# When enabled, uses Application Default Credentials (ADC) instead of API key
GOOGLE_CLOUD_USE_VERTEX_AI=false

# Optional: Custom Vertex AI endpoint URL
# VERTEX_AI_ENDPOINT="https://custom-vertex.googleapis.com"

# Vertex AI location (can differ from GOOGLE_LOCATION)
VERTEX_AI_LOCATION="us-central1"

# Prerequisites for Vertex AI:
# 1. Install Google Cloud SDK: https://cloud.google.com/sdk/docs/install
# 2. Authenticate: gcloud auth application-default login
# 3. Enable Vertex AI API in your Google Cloud project

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
LOG_LEVEL="INFO"
LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Available log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# PostgreSQL database connection (required for advanced features)
DATABASE_URL="postgresql://user:password@localhost/graphrag"

# Redis cache connection (optional, for distributed caching)
REDIS_URL="redis://localhost:6379"

# =============================================================================
# AUTHENTICATION & SECURITY
# =============================================================================
# Authentication mode: "none", "api_key", "jwt", "both"
# - none: No authentication (development only!)
# - api_key: Simple API key authentication (recommended)
# - jwt: JWT token-based authentication (advanced)
# - both: Support both API keys and JWT tokens
AUTH_MODE="api_key"

# Enable/disable authentication globally
AUTH_ENABLED=true

# -----------------------------------------------------------------------------
# DEFAULT ADMIN ACCESS (Quick Start)
# -----------------------------------------------------------------------------
# Default admin API key for immediate access (CHANGE IN PRODUCTION!)
# This key has full admin privileges - use for initial setup only
DEFAULT_ADMIN_API_KEY="grag_ak_default_admin_change_this_immediately"

# Default admin user (created on first startup if not exists)
DEFAULT_ADMIN_USERNAME="admin"
DEFAULT_ADMIN_EMAIL="admin@localhost"
DEFAULT_ADMIN_PASSWORD="admin123"  # Only used if JWT mode is enabled

# Auto-create default admin on startup
AUTO_CREATE_ADMIN=true

# -----------------------------------------------------------------------------
# API KEY CONFIGURATION
# -----------------------------------------------------------------------------
# API key prefix (helps identify keys in logs)
API_KEY_PREFIX="grag_ak_"

# API key length (excluding prefix)
API_KEY_LENGTH=32

# Default API key expiration (days, 0 = never expires)
API_KEY_EXPIRY_DAYS=365

# Allow API keys in query parameters (less secure, useful for webhooks)
API_KEY_ALLOW_QUERY_PARAM=false

# Rate limiting per API key (requests per minute)
API_KEY_RATE_LIMIT=100

# -----------------------------------------------------------------------------
# JWT CONFIGURATION (Advanced)
# -----------------------------------------------------------------------------
# JWT authentication settings
JWT_SECRET_KEY="your-secret-key-change-this-in-production"
JWT_ALGORITHM="HS256"
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# JWT issuer and audience
JWT_ISSUER="graphrag-api"
JWT_AUDIENCE="graphrag-users"

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
CONNECTION_POOL_SIZE=10
CONNECTION_POOL_MAX_OVERFLOW=20
CACHE_TTL=3600
MAX_WORKERS=4

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================
ENABLE_METRICS=true
ENABLE_TRACING=false
PROMETHEUS_PORT=9090

# =============================================================================
# RATE LIMITING
# =============================================================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=60

# =============================================================================
# CORS SETTINGS
# =============================================================================
# Use JSON array format for multiple origins
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8001"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["GET", "POST", "PUT", "DELETE", "OPTIONS"]
CORS_ALLOW_HEADERS=["*"]

# =============================================================================
# DEVELOPMENT NOTES
# =============================================================================
#
# Provider Selection Guidelines:
#
# Choose OLLAMA when you need:
# - Complete data privacy (local processing)
# - No external API costs
# - Offline operation capability
# - Simple setup for development
#
# Choose GOOGLE_GEMINI when you need:
# - High-performance cloud processing
# - Latest multimodal capabilities
# - Enterprise-grade reliability
# - Scalable production deployment
#
# Vertex AI vs Standard Gemini API:
# - Standard API: Requires API key, simpler authentication
# - Vertex AI: Uses ADC, better for enterprise/CI-CD, more advanced features
#
# =============================================================================
