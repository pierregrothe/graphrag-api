# GraphRAG API Service - Environment Configuration Template
# Copy this file to .env and configure your specific values

# =============================================================================
# API CONFIGURATION
# =============================================================================
APP_NAME="GraphRAG API Service"
APP_VERSION="0.1.0"
DEBUG=false

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
HOST="0.0.0.0"
PORT=8001

# =============================================================================
# GRAPHRAG CONFIGURATION
# =============================================================================
# Optional: Path to GraphRAG configuration file
# GRAPHRAG_CONFIG_PATH="/path/to/graphrag/config.yaml"

# Optional: Path to GraphRAG data directory
# GRAPHRAG_DATA_PATH="/path/to/graphrag/data"

# =============================================================================
# LLM PROVIDER SELECTION
# =============================================================================
# Choose your LLM provider: "ollama" or "google_gemini"
# For local development with privacy: use "ollama"
# For cloud deployment with high performance: use "google_gemini"
LLM_PROVIDER="ollama"

# =============================================================================
# OLLAMA CONFIGURATION (Local Provider)
# =============================================================================
# Ollama server configuration for local deployment
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_LLM_MODEL="gemma:4b"
OLLAMA_EMBEDDING_MODEL="nomic-embed-text"

# Prerequisites for Ollama:
# 1. Install Ollama: https://ollama.ai/
# 2. Pull models: ollama pull gemma:4b && ollama pull nomic-embed-text
# 3. Start Ollama service

# =============================================================================
# GOOGLE GEMINI CONFIGURATION (Cloud Provider)
# =============================================================================
# Google Cloud API configuration (required for google_gemini provider)
# GOOGLE_API_KEY="your_google_api_key_here"
# GOOGLE_PROJECT_ID="your_google_cloud_project_id"

# Google Cloud location (default: us-central1)
GOOGLE_LOCATION="us-central1"

# Gemini model configuration
GEMINI_MODEL="gemini-2.5-flash"
GEMINI_EMBEDDING_MODEL="text-embedding-004"

# =============================================================================
# VERTEX AI CONFIGURATION (Advanced Google Cloud)
# =============================================================================
# Enable Vertex AI endpoints instead of standard Gemini API
# When enabled, uses Application Default Credentials (ADC) instead of API key
GOOGLE_CLOUD_USE_VERTEX_AI=false

# Optional: Custom Vertex AI endpoint URL
# VERTEX_AI_ENDPOINT="https://custom-vertex.googleapis.com"

# Vertex AI location (can differ from GOOGLE_LOCATION)
VERTEX_AI_LOCATION="us-central1"

# Prerequisites for Vertex AI:
# 1. Install Google Cloud SDK: https://cloud.google.com/sdk/docs/install
# 2. Authenticate: gcloud auth application-default login
# 3. Enable Vertex AI API in your Google Cloud project

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
LOG_LEVEL="DEBUG"
LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Available log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL

# =============================================================================
# DEVELOPMENT NOTES
# =============================================================================
# 
# Provider Selection Guidelines:
# 
# Choose OLLAMA when you need:
# - Complete data privacy (local processing)
# - No external API costs
# - Offline operation capability
# - Simple setup for development
# 
# Choose GOOGLE_GEMINI when you need:
# - High-performance cloud processing
# - Latest multimodal capabilities
# - Enterprise-grade reliability
# - Scalable production deployment
# 
# Vertex AI vs Standard Gemini API:
# - Standard API: Requires API key, simpler authentication
# - Vertex AI: Uses ADC, better for enterprise/CI-CD, more advanced features
# 
# =============================================================================